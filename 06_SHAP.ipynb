{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZcpz/MWr2pdTDABiw8CRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OskarKrafft/Machine-Learning-Project/blob/main/06_SHAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgsf3tlRE_Z7",
        "outputId": "82d2930e-9ea3-4f06-b732-3c8191274504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project\n"
          ]
        }
      ],
      "source": [
        "# Mounting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory to project folder\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTmh44O0FPfv",
        "outputId": "6e326ef0-f241-401c-fe02-78cba451d088"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Test Data"
      ],
      "metadata": {
        "id": "Adpkt_WHFiJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the data\n",
        "import pandas as pd\n",
        "eppes_cleaned = pd.read_csv('./data/processed/eppes_cleaned.csv')\n",
        "eppes_cleaned = eppes_cleaned.drop(eppes_cleaned.columns[0], axis = 1)\n",
        "\n",
        "# Import Excel sheet containing column indeces to be dropped\n",
        "columns_analysis = pd.read_excel('./data/interim/Drop_Columns_categorical.xlsx')\n",
        "columns_analysis = columns_analysis.drop(columns_analysis.columns[[0]], axis = 1)\n",
        "\n",
        "# Create list of names of categorical columns \n",
        "col_names_categorical = []\n",
        "for i in range(872):\n",
        "  if columns_analysis.iloc[i, 3] == 'categorical':\n",
        "    col_names_categorical.append(columns_analysis.iloc[i, 1])\n",
        "\n",
        "# Change datatype of categorical variables to object\n",
        "eppes_cleaned[col_names_categorical] = eppes_cleaned[col_names_categorical].astype('object')\n",
        "\n",
        "# Define X and y\n",
        "print(eppes_cleaned.head())\n",
        "X = eppes_cleaned.drop(columns='qg1') # reference variable which contains voted y/n\n",
        "y = eppes_cleaned['qg1'] # reference variable which contains voted y/n\n",
        "\n",
        "# 80/20 train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state=123)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_test = label_encoder.fit_transform(y_test)\n",
        "\n",
        "y_test_df = pd.DataFrame(data=y_test)\n",
        "y_test_df.value_counts(normalize=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "\n",
        "y_train_df = pd.DataFrame(data=y_train)\n",
        "y_train_df.value_counts(normalize=True)\n",
        "\n",
        "# Setting up pre-processing pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Identify all categorical variables by data type\n",
        "categorical_X_features = X_test.select_dtypes(include=['object', 'bool']).columns\n",
        "\n",
        "# OneHotEncode all categorical variables\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"error\")\n",
        "\n",
        "preprocessor = ColumnTransformer(remainder = 'passthrough', # remainder = passthrough for numerical variables to be kept unchanged\n",
        "    transformers=[\n",
        "        (\"cat\", categorical_transformer, categorical_X_features)]\n",
        ")\n",
        "# Inspect the number of variables after pre-processing\n",
        "\n",
        "# Fit the pipeline to the testing data\n",
        "preprocessor.fit(X_test)\n",
        "X_test_ = preprocessor.transform(X_test)\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "preprocessor.fit(X_train)\n",
        "X_train_ = preprocessor.transform(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyKFRo8yFfvy",
        "outputId": "fe4a8272-1a65-4a95-877a-ddee6591cb31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   q1.1  q1.2  q1.3  q1.4  q1.5  q1.6  q1.7  q1.8  q1.9  q1.10  ...  d43a  \\\n",
            "0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "1   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "2   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0  ...   2.0   \n",
            "\n",
            "   d43b  d46.8  d60  d62_1  d62_2  d63  d72_1  d72_2  d77  \n",
            "0   1.0    1.0  1.0    3.0    6.0  1.0    3.0    3.0  2.0  \n",
            "1   1.0    1.0  3.0    2.0    6.0  3.0    2.0    2.0  3.0  \n",
            "2   2.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  1.0  \n",
            "3   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  1.0  \n",
            "4   1.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  3.0  \n",
            "\n",
            "[5 rows x 311 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Models"
      ],
      "metadata": {
        "id": "WCxZFl8lFux8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "best_rf = RandomForestClassifier(max_depth = 10, n_estimators = 300, min_samples_split = 5, min_samples_leaf = 1, max_features = \"sqrt\", random_state = 123)"
      ],
      "metadata": {
        "id": "uaKvPmHoFx0w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJP9q9wOGEpd",
        "outputId": "3548cae9-7394-4068-91f2-9a4d385420ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, max_features='sqrt', min_samples_split=5,\n",
              "                       n_estimators=300, random_state=123)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = best_rf.predict(X_test_)"
      ],
      "metadata": {
        "id": "h6KHPaiXib4Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef, f1_score, accuracy_score, precision_score, recall_score\n",
        "mcc = []\n",
        "f1 = []\n",
        "\n",
        "mcc.append((matthews_corrcoef(y_test, y_pred_rf)))\n",
        "f1.append((f1_score(y_test, y_pred_rf)))"
      ],
      "metadata": {
        "id": "bS5es02eij0t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcc\n",
        "f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHdI-iFrixjE",
        "outputId": "399b0985-d2e7-4ad0-9b7c-d7c4722cd2fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.802053388090349]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pip install fasttreeshap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByIBHymSHJeO",
        "outputId": "c759a21e-b7f8-45b2-f4fc-7b1a5e42f8c9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttreeshap\n",
            "  Downloading fasttreeshap-0.1.3.tar.gz (286 kB)\n",
            "\u001b[K     |████████████████████████████████| 286 kB 9.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (1.5.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (569 kB)\n",
            "\u001b[K     |████████████████████████████████| 569 kB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (5.4.8)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (21.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (0.56.4)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fasttreeshap) (1.7.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->fasttreeshap) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->fasttreeshap) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->fasttreeshap) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->fasttreeshap) (0.39.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->fasttreeshap) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->fasttreeshap) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fasttreeshap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fasttreeshap) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fasttreeshap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fasttreeshap) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fasttreeshap) (3.1.0)\n",
            "Building wheels for collected packages: fasttreeshap\n",
            "  Building wheel for fasttreeshap (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttreeshap: filename=fasttreeshap-0.1.3-cp37-cp37m-linux_x86_64.whl size=447262 sha256=5c8b3f64136d24918aaaf116d252bd2749ff8c492c81975a7da2c6ebdcf4e1b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/eb/8f/fafe68d53fcd042bb115ca09eea3733575b1439ae3db22f2dc\n",
            "Successfully built fasttreeshap\n",
            "Installing collected packages: slicer, shap, fasttreeshap\n",
            "Successfully installed fasttreeshap-0.1.3 shap-0.41.0 slicer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttreeshap "
      ],
      "metadata": {
        "id": "gA77QEW5GPJG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_explainer = fasttreeshap.TreeExplainer(best_rf, algorithm = \"auto\", n_jobs = -1)\n",
        "shap_values = shap_explainer(X_test_).values"
      ],
      "metadata": {
        "id": "1qF27K1aLF_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = fasttreeshap.TreeExplainer(best_rf, algorithm = \"auto\", n_jobs = -1)\n",
        "shap_test = explainer(X_test_)\n",
        "print(f\"Shap values length: {len(shap_test)}\\n\")\n",
        "print(f\"Sample shap value:\\n{shap_test[0]}\")"
      ],
      "metadata": {
        "id": "slDq9dlYxkQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_test)"
      ],
      "metadata": {
        "id": "-FlX5S5ularT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}