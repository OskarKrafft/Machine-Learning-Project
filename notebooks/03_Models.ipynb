{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OskarKrafft/Machine-Learning-Project/blob/main/notebooks/03_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N-3JmRnXZ1f"
      },
      "source": [
        "## Importing the clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZJPM0y797iW",
        "outputId": "594564d2-92a8-4fc5-cd64-ce5122c89f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project\n"
          ]
        }
      ],
      "source": [
        "# Mounting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4U_r8iUew7p"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW LOCATION EPPES. PLEASE REPLACE WHERE NECESSARY\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "eppes_new_loc = pd.read_csv('..\\data\\processed\\eppes_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "AWrMwwkD9mQR",
        "outputId": "0bf9a5e4-4c3c-4770-f77d-f1d5e4c332bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-de6cf926-f81a-4d75-a565-787de6d195a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1.1</th>\n",
              "      <th>q1.2</th>\n",
              "      <th>q1.3</th>\n",
              "      <th>q1.4</th>\n",
              "      <th>q1.5</th>\n",
              "      <th>q1.6</th>\n",
              "      <th>q1.7</th>\n",
              "      <th>q1.8</th>\n",
              "      <th>q1.9</th>\n",
              "      <th>q1.10</th>\n",
              "      <th>...</th>\n",
              "      <th>d43a</th>\n",
              "      <th>d43b</th>\n",
              "      <th>d46.8</th>\n",
              "      <th>d60</th>\n",
              "      <th>d62_1</th>\n",
              "      <th>d62_2</th>\n",
              "      <th>d63</th>\n",
              "      <th>d72_1</th>\n",
              "      <th>d72_2</th>\n",
              "      <th>d77</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27459</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27460</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27461</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27462</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27463</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27464 rows × 311 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de6cf926-f81a-4d75-a565-787de6d195a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de6cf926-f81a-4d75-a565-787de6d195a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de6cf926-f81a-4d75-a565-787de6d195a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       q1.1  q1.2  q1.3  q1.4  q1.5  q1.6  q1.7  q1.8  q1.9  q1.10  ...  d43a  \\\n",
              "0       1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "1       0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "2       1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
              "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0  ...   2.0   \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...   ...   \n",
              "27459   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "27460   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "27461   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
              "27462   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "27463   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "\n",
              "       d43b  d46.8  d60  d62_1  d62_2  d63  d72_1  d72_2  d77  \n",
              "0       1.0    1.0  1.0    3.0    6.0  1.0    3.0    3.0  2.0  \n",
              "1       1.0    1.0  3.0    2.0    6.0  3.0    2.0    2.0  3.0  \n",
              "2       2.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  1.0  \n",
              "3       1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  1.0  \n",
              "4       1.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  3.0  \n",
              "...     ...    ...  ...    ...    ...  ...    ...    ...  ...  \n",
              "27459   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  2.0  \n",
              "27460   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  2.0  \n",
              "27461   1.0    0.0  3.0    6.0    6.0  3.0    4.0    2.0  2.0  \n",
              "27462   1.0    1.0  2.0    6.0    6.0  4.0    2.0    2.0  2.0  \n",
              "27463   1.0    1.0  2.0    1.0    1.0  3.0    5.0    2.0  3.0  \n",
              "\n",
              "[27464 rows x 311 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing the data\n",
        "import pandas as pd\n",
        "eppes_cleaned = pd.read_csv('eppes_cleaned.csv')\n",
        "eppes_cleaned = eppes_cleaned.drop(eppes_cleaned.columns[0], axis = 1)\n",
        "eppes_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrzSyydGATmV",
        "outputId": "3db20a3f-f1e5-4708-e8f5-ceefb88ff27f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "float64    311\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eppes_cleaned.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW LOCATION. PLEASE REPLACE WHERE NECESSARY\n",
        "\n",
        "columns_analysis = pd.read_excel(r'..\\data\\interim\\Drop_Columns_categorical.xlsx')\n",
        "columns_analysis = columns_analysis.drop(columns_analysis.columns[[0]], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qsfsp4QEEOyo"
      },
      "outputs": [],
      "source": [
        "# Import Excel sheet containing column indeces to be dropped\n",
        "\n",
        "columns_analysis = pd.read_excel(r'Drop_Columns_categorical.xlsx')\n",
        "columns_analysis = columns_analysis.drop(columns_analysis.columns[[0]], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "08lp4wSUAU0o"
      },
      "outputs": [],
      "source": [
        "# Create list of names of categorical columns \n",
        "\n",
        "col_names_categorical = []\n",
        "\n",
        "for i in range(872):\n",
        "  if columns_analysis.iloc[i, 3] == 'categorical':\n",
        "    col_names_categorical.append(columns_analysis.iloc[i, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1tk38OrAYPw",
        "outputId": "2a3e779b-22ac-49bb-8e1d-8c3118c92945"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "object     167\n",
              "float64    144\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change datatype of categorical variables to object\n",
        "\n",
        "eppes_cleaned[col_names_categorical] = eppes_cleaned[col_names_categorical].astype('object')\n",
        "\n",
        "eppes_cleaned.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbUoAiPmGmj7",
        "outputId": "40ef16d5-4424-4ad5-cb38-aacab4e48c90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "object     167\n",
              "float64    144\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For test purposes: reduce to first X rows\n",
        "eppes_cleaned = eppes_cleaned[:15000]\n",
        "len(eppes_cleaned)\n",
        "\n",
        "# Examining data types \n",
        "eppes_cleaned.dtypes.value_counts() # only floats - fix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ww5qFbbX7s6"
      },
      "source": [
        "**Setting train and test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiCL2hxOv1fP",
        "outputId": "f154fcb2-28fe-4bf7-ecfd-04c504bef797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   q1.1  q1.2  q1.3  q1.4  q1.5  q1.6  q1.7  q1.8  q1.9  q1.10  ...  d43a  \\\n",
            "0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "1   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "2   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0  ...   2.0   \n",
            "\n",
            "   d43b  d46.8  d60  d62_1  d62_2  d63  d72_1  d72_2  d77  \n",
            "0   1.0    1.0  1.0    3.0    6.0  1.0    3.0    3.0  2.0  \n",
            "1   1.0    1.0  3.0    2.0    6.0  3.0    2.0    2.0  3.0  \n",
            "2   2.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  1.0  \n",
            "3   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  1.0  \n",
            "4   1.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  3.0  \n",
            "\n",
            "[5 rows x 311 columns]\n"
          ]
        }
      ],
      "source": [
        "# Define X and y\n",
        "print(eppes_cleaned.head())\n",
        "X = eppes_cleaned.drop(columns='qg1') # reference variable which contains voted y/n\n",
        "y = eppes_cleaned['qg1'] # reference variable which contains voted y/n\n",
        "\n",
        "# 80/20 train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHBWYXv82Dt-",
        "outputId": "a4430a37-d778-433d-e7c2-40854294f4c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.605417\n",
              "1    0.394583\n",
              "dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train\n",
        "y_train\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_train\n",
        "\n",
        "y_train_df = pd.DataFrame(data=y_train)\n",
        "y_train_df.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqxO1tsKZOfy"
      },
      "source": [
        "**Defining the pre-processing steps** \n",
        "\n",
        "All categorical variables are OneHotEncoded. Age is the only truly continuous variable in our dataset, which is already normally distributed and positive. Thus, we do not employ any transformation of the numerical variables. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cATESRMVQDZ9"
      },
      "outputs": [],
      "source": [
        "# Setting up pre-processing pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Identify all categorical variables by data type\n",
        "categorical_X_features = X_train.select_dtypes(include=['object', 'bool']).columns\n",
        "\n",
        "# OneHotEncode all categorical variables\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"error\")\n",
        "\n",
        "preprocessor = ColumnTransformer(remainder = 'passthrough', # remainder = passthrough for numerical variables to be kept unchanged\n",
        "    transformers=[\n",
        "        (\"cat\", categorical_transformer, categorical_X_features)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "_eJ6L3I29mQX",
        "outputId": "4938b110-07e0-432f-f09a-7fde7b346e52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2e00a3a1-5edd-4caa-897b-aea2e44c2fc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>925</th>\n",
              "      <th>926</th>\n",
              "      <th>927</th>\n",
              "      <th>928</th>\n",
              "      <th>929</th>\n",
              "      <th>930</th>\n",
              "      <th>931</th>\n",
              "      <th>932</th>\n",
              "      <th>933</th>\n",
              "      <th>934</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "      <td>12000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.323667</td>\n",
              "      <td>0.540917</td>\n",
              "      <td>0.107583</td>\n",
              "      <td>0.026083</td>\n",
              "      <td>0.001750</td>\n",
              "      <td>0.267583</td>\n",
              "      <td>0.522917</td>\n",
              "      <td>0.207417</td>\n",
              "      <td>0.002083</td>\n",
              "      <td>0.179917</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027333</td>\n",
              "      <td>0.040500</td>\n",
              "      <td>0.147417</td>\n",
              "      <td>0.035000</td>\n",
              "      <td>0.044083</td>\n",
              "      <td>1.507750</td>\n",
              "      <td>52.089083</td>\n",
              "      <td>2.123500</td>\n",
              "      <td>0.248833</td>\n",
              "      <td>0.808250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.467894</td>\n",
              "      <td>0.498344</td>\n",
              "      <td>0.309866</td>\n",
              "      <td>0.159390</td>\n",
              "      <td>0.041798</td>\n",
              "      <td>0.442718</td>\n",
              "      <td>0.499495</td>\n",
              "      <td>0.405473</td>\n",
              "      <td>0.045598</td>\n",
              "      <td>0.384134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.163060</td>\n",
              "      <td>0.197137</td>\n",
              "      <td>0.354536</td>\n",
              "      <td>0.183787</td>\n",
              "      <td>0.205289</td>\n",
              "      <td>0.499961</td>\n",
              "      <td>18.470867</td>\n",
              "      <td>1.089042</td>\n",
              "      <td>0.700683</td>\n",
              "      <td>0.393694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 935 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e00a3a1-5edd-4caa-897b-aea2e44c2fc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e00a3a1-5edd-4caa-897b-aea2e44c2fc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e00a3a1-5edd-4caa-897b-aea2e44c2fc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                0             1             2             3             4    \\\n",
              "count  12000.000000  12000.000000  12000.000000  12000.000000  12000.000000   \n",
              "mean       0.323667      0.540917      0.107583      0.026083      0.001750   \n",
              "std        0.467894      0.498344      0.309866      0.159390      0.041798   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "75%        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                5             6             7             8             9    \\\n",
              "count  12000.000000  12000.000000  12000.000000  12000.000000  12000.000000   \n",
              "mean       0.267583      0.522917      0.207417      0.002083      0.179917   \n",
              "std        0.442718      0.499495      0.405473      0.045598      0.384134   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "75%        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "       ...           925           926           927           928  \\\n",
              "count  ...  12000.000000  12000.000000  12000.000000  12000.000000   \n",
              "mean   ...      0.027333      0.040500      0.147417      0.035000   \n",
              "std    ...      0.163060      0.197137      0.354536      0.183787   \n",
              "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                929           930           931           932           933  \\\n",
              "count  12000.000000  12000.000000  12000.000000  12000.000000  12000.000000   \n",
              "mean       0.044083      1.507750     52.089083      2.123500      0.248833   \n",
              "std        0.205289      0.499961     18.470867      1.089042      0.700683   \n",
              "min        0.000000      1.000000     15.000000      1.000000      0.000000   \n",
              "25%        0.000000      1.000000     37.000000      1.000000      0.000000   \n",
              "50%        0.000000      2.000000     53.000000      2.000000      0.000000   \n",
              "75%        0.000000      2.000000     67.000000      2.000000      0.000000   \n",
              "max        1.000000      2.000000     98.000000     20.000000     20.000000   \n",
              "\n",
              "                934  \n",
              "count  12000.000000  \n",
              "mean       0.808250  \n",
              "std        0.393694  \n",
              "min        0.000000  \n",
              "25%        1.000000  \n",
              "50%        1.000000  \n",
              "75%        1.000000  \n",
              "max        1.000000  \n",
              "\n",
              "[8 rows x 935 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspect the number of variables after pre-processing\n",
        "# Fit the pipeline to the training data\n",
        "preprocessor.fit(X_train)\n",
        "X_train_ = preprocessor.transform(X_train)\n",
        "\n",
        "X_train_df = pd.DataFrame(data=X_train_)\n",
        "X_train_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBFgZlBkyl2p"
      },
      "source": [
        "### Model 1 (Baseline): Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C0154btCRIEf"
      },
      "outputs": [],
      "source": [
        "# Define a pipeline with pre-processing and a Logistic Regression\n",
        "logistic_regression_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter = 200))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrMb4C8TJ-t-",
        "outputId": "599dba2d-9fb6-44a6-ff68-8dd4e29c1ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.793655 using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.793420 (0.010879) with: {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.793655 (0.010968) with: {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.793481 (0.011070) with: {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}\n",
            "0.786915 (0.011901) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.787034 (0.011784) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.787020 (0.011777) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}\n",
            "0.782515 (0.011503) with: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.782343 (0.011968) with: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.782299 (0.012097) with: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}\n",
            "0.781987 (0.011847) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.781140 (0.012734) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.781065 (0.012508) with: {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}\n",
            "0.781599 (0.012408) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.780701 (0.012983) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.780703 (0.013115) with: {'classifier__C': 100, 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}\n"
          ]
        }
      ],
      "source": [
        "# Tune the hyperparameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define parameters for optimisiation\n",
        "solvers = ['lbfgs', 'liblinear', 'newton-cg'] # algorithms used to solve the optimization problem\n",
        "penalty = ['l2'] # specifying penaltty - limited to l2 as other penalties not compatible with all solvers\n",
        "c_values = [0.0001, 0.001, 0.01, 0.1] # inverse of regularization strength (smaller values = stronger regularization)\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__solver':solvers, \n",
        "    'classifier__penalty':penalty,\n",
        "    'classifier__C':c_values}\n",
        "\n",
        "# Set-up repeated, stratified cross-validation \n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
        "\n",
        "# Define GridSearchCV with F1 as comparison metrics\n",
        "grid_search = GridSearchCV(estimator=logistic_regression_pipe, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1')\n",
        "\n",
        "# Fit the grid search model\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the mean test scrore (F1), sd and the parameters that were used\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_0qmTlj4jo3",
        "outputId": "c18f1164-fb60-427d-be30-cc74b2602c43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['best-logistic-regression.joblib']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Document the best model specification as a vector\n",
        "from joblib import dump, load\n",
        "\n",
        "estimator = grid_result.best_estimator_\n",
        "dump(estimator, \"best-logistic-regression.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW3Rp9uRJvQ1",
        "outputId": "5b3c4c7f-cb5c-4595-9959-9456a6c90df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.88      7265\n",
            "           1       0.85      0.77      0.81      4735\n",
            "\n",
            "    accuracy                           0.86     12000\n",
            "   macro avg       0.86      0.84      0.85     12000\n",
            "weighted avg       0.86      0.86      0.85     12000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get classification report on best performing logistic regression model\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "best_logistic_regression = load(\"best-logistic-regression.joblib\")\n",
        "best_logistic_regression.fit(X_train, y_train)\n",
        "\n",
        "y_pred_logistic = best_logistic_regression.predict(X_train) # need to change to X_test in final run\n",
        "print(classification_report(y_train, y_pred_logistic)) \n",
        "\n",
        "### TBD whether to report visualised classification report - currently somehow the smaller class is not displayed\n",
        "# from yellowbrick.classifier import ClassificationReport\n",
        "# visualizer = ClassificationReport(best_logistic_regression, support = True)\n",
        "# visualizer.fit(X_train, y_train)  \n",
        "# visualizer.score(X_test, y_test)\n",
        "# visualizer.poof()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfqsH6Vuyter"
      },
      "source": [
        "### Model 2: Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EWOuMM6tgyFi"
      },
      "outputs": [],
      "source": [
        "# Bernoulli NB seems most suitable, as we OneHotEncode all our ordinal data\n",
        "# Alternatives are less relevant, e.g. GaussianNB is for continuous features and CategoricalNB for categorical features\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# Define a pipeline with pre-processing and a Bernoulli Naive Bayes\n",
        "naive_bayes_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", BernoulliNB())]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ-Cg-wUtUpa"
      },
      "source": [
        "### Model 3: Support Vector Machine (SVM) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UTp9ZecFtl2A"
      },
      "outputs": [],
      "source": [
        "# Define a pipeline with pre-processing and SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC())]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1II1_71s_Lj"
      },
      "source": [
        "### Model 4: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XcbJwdgP-pCG"
      },
      "outputs": [],
      "source": [
        "# Define a pipeline with pre-processing and Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier(random_state = 123))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jaoHhXuW-ppj",
        "outputId": "f712f664-86d5-47e6-eda8-44388112094e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0bbe75f4d131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Define GridSearchCV with F1 as comparison metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrf_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# set number of iterations to 5 from the default of 10 for faster computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random_forest_pipe' is not defined"
          ]
        }
      ],
      "source": [
        "# Define parameters for optimisiation\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)] # number of trees in the random forest\n",
        "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # maximum number of levels allowed in each decision tree\n",
        "min_samples_split = [2, 5, 10] # minimum sample number to split a node\n",
        "min_samples_leaf = [1, 2, 4] # minimum sample number that can be stored in a leaf node\n",
        "\n",
        "random_grid = {\n",
        "    'classifier__n_estimators':n_estimators, \n",
        "    'classifier__max_features':max_features,\n",
        "    'classifier__max_depth':max_depth,\n",
        "    'classifier__min_samples_split':min_samples_split,\n",
        "    'classifier__min_samples_leaf': min_samples_leaf}\n",
        "\n",
        "# Set-up repeated, stratified cross-validation \n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=123) # set n_splits to 5 for faster computation, tbd if increase for final run\n",
        "\n",
        "# Define GridSearchCV with F1 as comparison metrics\n",
        "rf_random = RandomizedSearchCV(estimator = random_forest_pipe, param_distributions=random_grid, cv=cv, n_iter=20, random_state=123, n_jobs = -1) \n",
        "# set number of iterations to 5 from the default of 10 for faster computation \n",
        "\n",
        "# Fit the grid search model\n",
        "rf_random_result = rf_random.fit(X_train, y_train)\n",
        "\n",
        "# Print the mean test scrore (F1), sd and the parameters that were used\n",
        "print(\"Best: %f using %s\" % (rf_random_result.best_score_, rf_random_result.best_params_))\n",
        "means = rf_random_result.cv_results_['mean_test_score']\n",
        "stds = rf_random_result.cv_results_['std_test_score']\n",
        "params = rf_random_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "vz8u3gQ6vnk2",
        "outputId": "b1e39c99-9a9b-4e8b-af39-917e90ecf1f5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-622b967cca29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Document the best model specification as a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_random_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best-random-forest.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rf_random_result' is not defined"
          ]
        }
      ],
      "source": [
        "# Document the best model specification as a vector\n",
        "estimator = rf_random_result.best_estimator_\n",
        "dump(estimator, \"best-random-forest.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDCTYXsTozY9"
      },
      "source": [
        "**Comparing the best performing models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "jyliL1IDHbrr",
        "outputId": "fc840fb1-fa63-4612-aab2-98b5530eafec"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a0f631286440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load all the model specifications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best-logistic-regression.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Naive Bayes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaive_bayes_pipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best-SVM.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load' is not defined"
          ]
        }
      ],
      "source": [
        "# Compare best performing models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load all the model specifications\n",
        "models = []\n",
        "models.append(('Logistic Regression', load(\"best-logistic-regression.joblib\")))\n",
        "models.append(('Naive Bayes', naive_bayes_pipe))\n",
        "models.append(('SVM', load(\"best-SVM.joblib\")))\n",
        "\n",
        "# Create lists for scores and model names. Comparison metric F1\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'f1'\n",
        "\n",
        "for name, model in models:\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
        "  cv_results = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring) # change to x test and y test in final run\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "yZArDfjZo8gB",
        "outputId": "cd47eb77-0d4f-42ec-ceb8-b5f01fde6c01"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUGElEQVR4nO3df7RdZX3n8feHAGWs/EhM6lIIJNb4I1Ydxzuoo2vJ1B+D1obp6LiC03FQC8uZQezUdgpdrUZaq+3Udla7wGmq1iq0iMxoU0tFrbK0VjEXUceAOJlUJgGsAQIo/oDAd/44O3g43HtzEu4+h9zn/VrrrHX2fp6z93ffnJzP2fs55zypKiRJ7Tps2gVIkqbLIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBoIelJGuSVJLDx+h7RpK/m0Rdk5bkfyT5jWnXoaXNINBDluSbSe5OsnJk/TXdi/ma6VR2fx1HJtmU5P8kuaur973TrmscVfX6qvrNae1/KJC/O3T7Stf2mCRbktz0cPh31sEzCLRY/gE4fd9CkqcCj5heOQ9wGbABeBVwLPB04GrgBdMsan+SLJt2DUOOq6pHdrend+vuAz4GvHyKdWkRGARaLB8AXj20/B+A9w93SHJskvcn2Z3khiS/nuSwrm1Zkt9LckuSHcDPzPHY9yS5OcmNSX5rnBfKJC8EXgScVlVbq2pvVd1RVRdU1Xu6Po/t3tnelmR7kjOHHr8pyYeSXJTkO0n+d5InJDkvybeT7Ezy4qH+VyZ5e5IvJrkzyV8mWTHU/qEk30pyR5LPJHnKUNv7krwryeVJ7gL+Zbfut7r2lUk+muT2rtbPDv39ntzt+/Yk25JsGNnuBUn+ujuGq5L85P7+dvtTVf9YVRcCWx/qtjRdBoEWyxeAY7oXpGXARuCikT5/xOAd+eOA5zMIjtd0bWcCLwOeAcwArxh57PuAvcDjuz4vBn5hjLpeCHyxqnYu0OcSYBfw2G6/v53kp4faf5ZB0C0HrgGuYPB/53jgfOCPR7b3auC1wGO6mv9wqO1vgHXATwBfAi4eeeyrgLcBRwOj4x5v6upcBTwa+DWgkhwB/BXw8W67bwAuTvLEocduBN7aHcP2bh8AdOFy7px/GTXBINBi2ndW8CLgOuDGfQ1D4XBeVX2nqr4JvBP4912XVwL/vap2VtVtwNuHHvto4KXAL1bVXVX1beAPuu3tz6OAm+drTLIaeC7wq1X1g6r6MvBuHnh289mquqKq9gIfYvBC/I6quodBiKxJctzw36GqvlZVdwG/Abxy39lLVb23O/4fApuApyc5duixf1lVn6uq+6rqByPl3sMgXE6qqnuq6rM1+LGwZwOP7Gq6u6o+BXyUoUt1wIer6ovdMVwM/NN9DVX1sqp6xwJ/Q4BburON25P88n766hCz309kSAfgA8BngLWMXBYCVgJHADcMrbuBwbtqGLwb3znSts9J3WNvTrJv3WEj/edzK/CEBdofC9xWVd8Z2ffM0PI/Dt3/PnBLVd07tAyDF+Lbu/ujx3EEsDLJLQzeif9bBmFyX9dnJXDHHI8d9d8YhMfHu7/D5u4F/LHAzqq6b6jv8N8W4FtD97/X1XsgVnYhoiXIMwItmqq6gcGg8UuB/zXSfAuDd7QnDa07kR+dNdwMrB5p22cn8EMGL0bHdbdjquop7N8ngZOTnDBP+03AiiRHz1PXwRg9jnsYHP+rgNMYXK46FljT9clQ/3l/Drg7k3hTVT2OweD3LyV5QXcMq/eNFyzSMaghBoEW2+uAn+4ui9yvewd9KfC2JEcnOQn4JX40jnApcE6SE5IsB84deuzNDK5/vzPJMUkOS/KTSZ6/v2Kq6pPAJ4APJ3lmksO7/b8+yWu7sYO/B96e5KgkT+uOYXR840D8fJL1SR7BYAzhsu74j2YQaLcy+ETVbx/IRpO8LMnjMzgduAO4l8FZxVUM3uX/1yRHJDmFwbjGJQ/hGMat6Sjgx7rFH+uWdYgxCLSoqur/VtXsPM1vAO4CdjAYCP1z4L1d258wGIT9CoNB1NEzilcDRwLXAnsYfCT0MWOW9QrgcuCDDF5Av8bg0s8nu/bTGbw7vwn4MPCWLkAO1gcYDG5/CzgKOKdb/34Gl2xu7I7jCwe43XVdzd8FPg9cWFWfrqq7Gbzwv4TBmceFwKur6uvjbDTJ3yT5tQOsZZ/vd/UAfJ0fXSrTISROTCMtniRXAhdV1bunXYs0Ls8IJKlxBoEkNc5LQ5LUOM8IJKlxh9wXylauXFlr1qyZdhmSdEi5+uqrb6mqVXO1HXJBsGbNGmZn5/t0oiRpLklumK/NS0OS1DiDQJIaZxBIUuMMAklqnEEgSY3rNQiSnJrk+m76vwfNgJTkpCR/m+Sr3TR78/1UsCSpJ70FQTcj0wUMfhFxPXB6kvUj3X4PeH9VPY3Bz/W+HUnSRPV5RnAysL2qdnQ/k3sJg0k5hq0HPtXd//Qc7ZKknvUZBMfzwGn3dvHAqfNg8Nvz/6a7/3PA0UkeNbqhJGclmU0yu3v37l6KXcqSHNRNUhumPVj8y8Dzk1wDPJ/BhB33jnaqqs1VNVNVM6tWzfkNaS2gqua9LdQuqQ19/sTEjTxw7tYTGJlDtapuojsjSPJI4OVVdTuSpInp84xgK7AuydokRwIbgS3DHZKsHJpw+zx+NG2hJGlCeguCqtoLnM1gHtrrgEuraluS85Ns6LqdAlyf5BvAo4G39VWPJGluh9zENDMzM+Wvjy6eJI4HSA1IcnVVzczVNu3BYknSlBkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIlpAVK1Yc1LzEB9J/xYoVUz5KSYutz6kqNWF79uzpfW4BJ7WXlh7PCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWpcr0GQ5NQk1yfZnuTcOdpPTPLpJNck+WqSl/ZZjyTpwXoLgiTLgAuAlwDrgdOTrB/p9uvApVX1DGAjcGFf9UiS5tbnGcHJwPaq2lFVdwOXAKeN9CngmO7+scBNPdYjSZpDn1NVHg/sHFreBTxrpM8m4ONJ3gD8OPDCuTaU5CzgLIATTzxx0QtdKuotx8CmY/vfh7SIDmb6076nZG3NtOcsPh14X1W9M8lzgA8k+amqum+4U1VtBjYDzMzM+AyYR95650TmLK5Nve5CjZnvOZvEF/wJ6fPS0I3A6qHlE7p1w14HXApQVZ8HjgJW9liTJGlEn0GwFViXZG2SIxkMBm8Z6fP/gBcAJHkygyDY3WNNkqQRvQVBVe0FzgauAK5j8OmgbUnOT7Kh6/Ym4MwkXwH+AjijPBeUpInqdYygqi4HLh9Z9+ah+9cCz+2zBknSwvxmsSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWpcr0GQ5NQk1yfZnuTcOdr/IMmXu9s3ktzeZz2SpAc7vK8NJ1kGXAC8CNgFbE2ypaqu3denqv7LUP83AM/oqx5J0tz6PCM4GdheVTuq6m7gEuC0BfqfDvxFj/VIkubQZxAcD+wcWt7VrXuQJCcBa4FPzdN+VpLZJLO7d+9e9EIl9W/FihUkGfsGHFD/JKxYsWLKR3loGisIkjwvyWu6+6uSrF3kOjYCl1XVvXM1VtXmqpqpqplVq1Yt8q4lTcKePXuoql5ve/bsmfZhHpL2GwRJ3gL8KnBet+oI4KIxtn0jsHpo+YRu3Vw24mUhSZqKcc4Ifg7YANwFUFU3AUeP8bitwLoka5McyeDFfstopyRPApYDnx+3aEnS4hknCO6uqgIKIMmPj7PhqtoLnA1cAVwHXFpV25Kcn2TDUNeNwCXdPiRJEzbOx0cvTfLHwHFJzgReC/zJOBuvqsuBy0fWvXlkedN4pUqS+rBgEGQwdP9B4EnAncATgTdX1ScmUJskaQIWDIKqqiSXV9VTAV/8JWkJGmeM4EtJ/nnvlUiSpmKcMYJnAf8uyQ0MPjkUBicLT+u1MknSRIwTBP+q9yokSVOz30tDVXUDcBzws93tuG6dJGkJGOebxW8ELgZ+ortd1P1SqCRpCRjn0tDrgGdV1V0ASX6HwbeA/6jPwiRJkzHOp4YCDP8Y3L3dOknSEjDOGcGfAlcl+XC3/K+B9/RXkiRpkvYbBFX1+0muBJ7XrXpNVV3Ta1WSpInZbxAkeTawraq+1C0fk+RZVXVV79VJkno3zhjBu4DvDi1/t1snSVoCxhosHv6J6Kq6jx4nvZckTdY4QbAjyTlJjuhubwR29F2YJGkyxgmC1wP/gsE0k7sY/PbQWX0WJUmanHE+NfRtBrOISZKWoHF+YuJ3u08KHZHkb5PsTvLzkyhOktS/cS4Nvbiq7gReBnwTeDzwK30WJUmanHGCYN/lo58BPlRVd/RYjyRpwsb5GOhHk3wd+D7wH5OsAn7Qb1mSpEkZZz6Ccxl8amimqu4Bvgec1ndhkqTJGOuLYVV129D9uxhMWSlJWgLGGSOQJC1hBoEkNe6ggiDJkxa7EEnSdBzsGcHHF7UKSdLUzDtYnOQP52sCjuunHEnSpC30qaHXAG8CfjhH2+n9lCNJmrSFgmAr8LWq+vvRhiSbeqtIkjRRCwXBK5jnG8RVtbafciRJk7bQYPEjq+p7D2XjSU5Ncn2S7UnOnafPK5Ncm2Rbkj9/KPuTJB24hYLgI/vuJPmfB7rhJMuAC4CXAOuB05OsH+mzDjgPeG5VPQX4xQPdjyTpoVkoCDJ0/3EHse2Tge1VtaOq7gYu4cG/UXQmcEFV7YH7J8GRJE3QQmMENc/9cR0P7Bxa3jfN5bAnACT5HLAM2FRVHxvdUJKz6KbHPPHEEw+ilHYk2X+nh2D58uW9bl9LV73lGNh0bP/70AFbKAienuROBmcG/6S7T7dcVbUYf/HDgXXAKcAJwGeSPLWqbh/uVFWbgc0AMzMzBxNKTag68D9NkoN6nHSg8tY7e3+uJaE29bqLJWneIKiqZQ9x2zcCq4eWT+jWDdsFXNX9vPU/JPkGg2DY+hD3LUkaU58/OrcVWJdkbZIjgY3AlpE+H2FwNkCSlQwuFe3osSZJ0ojegqCq9gJnA1cA1wGXVtW2JOcn2dB1uwK4Ncm1wKeBX6mqW/uqSZL0YDnUrg/PzMzU7OzstMtYMhwj0KRM4rnm83l+Sa6uqpm52pyPQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDWu1yBIcmqS65NsT3LuHO1nJNmd5Mvd7Rf6rEeS9GCH97XhJMuAC4AXAbuArUm2VNW1I10/WFVn91WHJGlhfZ4RnAxsr6odVXU3cAlwWo/7kyQdhD6D4Hhg59Dyrm7dqJcn+WqSy5KsnmtDSc5KMptkdvfu3X3UKmkCkvR6W758+bQP8ZA07cHivwLWVNXTgE8AfzZXp6raXFUzVTWzatWqiRYoaXFU1QHdDuYxt91225SP8tDUZxDcCAy/wz+hW3e/qrq1qn7YLb4beGaP9UiS5tBnEGwF1iVZm+RIYCOwZbhDkscMLW4AruuxHknSHHr71FBV7U1yNnAFsAx4b1VtS3I+MFtVW4BzkmwA9gK3AWf0VY8kaW7Zdy3uUDEzM1Ozs7PTLmPJSMKh9hxQG3xuLq4kV1fVzFxt0x4sliRNmUEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGtdrECQ5Ncn1SbYnOXeBfi9PUklm+qxHkvRgvQVBkmXABcBLgPXA6UnWz9HvaOCNwFV91SJJml+fZwQnA9urakdV3Q1cApw2R7/fBH4H+EGPtUiS5tFnEBwP7Bxa3tWtu1+Sfwasrqq/XmhDSc5KMptkdvfu3Ytf6RKXZN7bQu3SJPjcnL7Dp7XjJIcBvw+csb++VbUZ2AwwMzNT/Va29FT5J9PDl8/P6evzjOBGYPXQ8gndun2OBn4KuDLJN4FnA1scMJakyeozCLYC65KsTXIksBHYsq+xqu6oqpVVtaaq1gBfADZU1WyPNUmSRvQWBFW1FzgbuAK4Dri0qrYlOT/Jhr72K0k6ML2OEVTV5cDlI+vePE/fU/qsRZI0N79ZLEmNMwgkqXEGgSQ1ziCQpMblUPsyR5LdwA3TrmMJWQncMu0ipDn43FxcJ1XVqrkaDrkg0OJKMltVfolPDzs+NyfHS0OS1DiDQJIaZxBo87QLkObhc3NCHCOQpMZ5RiBJjTMIJKlxBoGkh5Uka5J8bdp1tMQgkKTGGQSNSvKRJFcn2ZbkrGnXI404PMnFSa5LclmSR0y7oKXMIGjXa6vqmcAMcE6SR027IGnIE4ELq+rJwJ3Af5pyPUuaQdCuc5J8hcEUoauBdVOuRxq2s6o+192/CHjeNItZ6nqdoUwPT0lOAV4IPKeqvpfkSuCoqRYlPdDoF5z8wlOPPCNo07HAni4EngQ8e9oFSSNOTPKc7v6rgL+bZjFLnUHQpo8xGIy7DngHg8tD0sPJ9cB/7p6jy4F3TbmeJc2fmJCkxnlGIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4/4/pEr4F+PNt7cAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the model performance as boxplot\n",
        "# TBD: Have MCC in the same boxplot, make nicer\n",
        "\n",
        "x1 = [0.9, 0.8, 0.4]\n",
        "x2 = [0.8, 0.4, 0.6]\n",
        "names = [\"a\", \"b\", \"c\"]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot([x1, x2])\n",
        "ax.set_title(\"Model Comparison: F1\")\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_ylabel(\"F1 score\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 ('Machine-Learning-Project-K3kAtfCK')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d776d6ed3af7d3b49847a0099a298aa8d78d20c8f42c0601505d3117fd4dfc67"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
