{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OskarKrafft/Machine-Learning-Project/blob/main/notebooks/03_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N-3JmRnXZ1f"
      },
      "source": [
        "## Importing the clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZJPM0y797iW",
        "outputId": "4967e9fd-2451-4aa1-8b8d-75ad9449a358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project\n"
          ]
        }
      ],
      "source": [
        "# Mounting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "AWrMwwkD9mQR",
        "outputId": "814bb49b-cc73-4ba1-c86f-67c1c7238f1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       q1.1  q1.2  q1.3  q1.4  q1.5  q1.6  q1.7  q1.8  q1.9  q1.10  ...  d43a  \\\n",
              "0       1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "1       0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "2       1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
              "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0  ...   2.0   \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...   ...   \n",
              "27459   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "27460   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "27461   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
              "27462   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "27463   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
              "\n",
              "       d43b  d46.8  d60  d62_1  d62_2  d63  d72_1  d72_2  d77  \n",
              "0       1.0    1.0  1.0    3.0    6.0  1.0    3.0    3.0  2.0  \n",
              "1       1.0    1.0  3.0    2.0    6.0  3.0    2.0    2.0  3.0  \n",
              "2       2.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  1.0  \n",
              "3       1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  1.0  \n",
              "4       1.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  3.0  \n",
              "...     ...    ...  ...    ...    ...  ...    ...    ...  ...  \n",
              "27459   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  2.0  \n",
              "27460   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  2.0  \n",
              "27461   1.0    0.0  3.0    6.0    6.0  3.0    4.0    2.0  2.0  \n",
              "27462   1.0    1.0  2.0    6.0    6.0  4.0    2.0    2.0  2.0  \n",
              "27463   1.0    1.0  2.0    1.0    1.0  3.0    5.0    2.0  3.0  \n",
              "\n",
              "[27464 rows x 311 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12292486-efc1-418e-ae52-08fea58f35c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1.1</th>\n",
              "      <th>q1.2</th>\n",
              "      <th>q1.3</th>\n",
              "      <th>q1.4</th>\n",
              "      <th>q1.5</th>\n",
              "      <th>q1.6</th>\n",
              "      <th>q1.7</th>\n",
              "      <th>q1.8</th>\n",
              "      <th>q1.9</th>\n",
              "      <th>q1.10</th>\n",
              "      <th>...</th>\n",
              "      <th>d43a</th>\n",
              "      <th>d43b</th>\n",
              "      <th>d46.8</th>\n",
              "      <th>d60</th>\n",
              "      <th>d62_1</th>\n",
              "      <th>d62_2</th>\n",
              "      <th>d63</th>\n",
              "      <th>d72_1</th>\n",
              "      <th>d72_2</th>\n",
              "      <th>d77</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27459</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27460</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27461</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27462</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27463</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27464 rows × 311 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12292486-efc1-418e-ae52-08fea58f35c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12292486-efc1-418e-ae52-08fea58f35c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12292486-efc1-418e-ae52-08fea58f35c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Importing the data\n",
        "import pandas as pd\n",
        "eppes_cleaned = pd.read_csv('./data/processed/eppes_cleaned.csv')\n",
        "eppes_cleaned = eppes_cleaned.drop(eppes_cleaned.columns[0], axis = 1)\n",
        "eppes_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qsfsp4QEEOyo"
      },
      "outputs": [],
      "source": [
        "# Import Excel sheet containing column indeces to be dropped\n",
        "\n",
        "columns_analysis = pd.read_excel('./data/interim/Drop_Columns_categorical.xlsx')\n",
        "columns_analysis = columns_analysis.drop(columns_analysis.columns[[0]], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "08lp4wSUAU0o"
      },
      "outputs": [],
      "source": [
        "# Create list of names of categorical columns \n",
        "\n",
        "col_names_categorical = []\n",
        "\n",
        "for i in range(872):\n",
        "  if columns_analysis.iloc[i, 3] == 'categorical':\n",
        "    col_names_categorical.append(columns_analysis.iloc[i, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1tk38OrAYPw",
        "outputId": "be762a9e-425e-43cc-8f25-4bc215e0c29e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "object     167\n",
              "float64    144\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Change datatype of categorical variables to object\n",
        "\n",
        "eppes_cleaned[col_names_categorical] = eppes_cleaned[col_names_categorical].astype('object')\n",
        "\n",
        "eppes_cleaned.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ww5qFbbX7s6"
      },
      "source": [
        "**Setting train and test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiCL2hxOv1fP",
        "outputId": "4f27f897-e1c6-4dea-8e42-7e06391176dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   q1.1  q1.2  q1.3  q1.4  q1.5  q1.6  q1.7  q1.8  q1.9  q1.10  ...  d43a  \\\n",
            "0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "1   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "2   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0  ...   2.0   \n",
            "\n",
            "   d43b  d46.8  d60  d62_1  d62_2  d63  d72_1  d72_2  d77  \n",
            "0   1.0    1.0  1.0    3.0    6.0  1.0    3.0    3.0  2.0  \n",
            "1   1.0    1.0  3.0    2.0    6.0  3.0    2.0    2.0  3.0  \n",
            "2   2.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  1.0  \n",
            "3   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  1.0  \n",
            "4   1.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  3.0  \n",
            "\n",
            "[5 rows x 311 columns]\n"
          ]
        }
      ],
      "source": [
        "# Define X and y\n",
        "print(eppes_cleaned.head())\n",
        "X = eppes_cleaned.drop(columns='qg1') # reference variable which contains voted y/n\n",
        "y = eppes_cleaned['qg1'] # reference variable which contains voted y/n\n",
        "\n",
        "# 80/20 train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHBWYXv82Dt-",
        "outputId": "003a4d8b-39bd-47c3-ba37-5e85ea2ddc68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.547676\n",
              "1    0.452324\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train\n",
        "y_train\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_train\n",
        "\n",
        "y_train_df = pd.DataFrame(data=y_train)\n",
        "y_train_df.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqxO1tsKZOfy"
      },
      "source": [
        "**Defining the pre-processing steps** \n",
        "\n",
        "All categorical variables are OneHotEncoded. Age is the only truly continuous variable in our dataset, which is already normally distributed and positive. Thus, we do not employ any transformation of the numerical variables. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cATESRMVQDZ9"
      },
      "outputs": [],
      "source": [
        "# Setting up pre-processing pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Identify all categorical variables by data type\n",
        "categorical_X_features = X_train.select_dtypes(include=['object', 'bool']).columns\n",
        "\n",
        "# OneHotEncode all categorical variables\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"error\")\n",
        "\n",
        "preprocessor = ColumnTransformer(remainder = 'passthrough', # remainder = passthrough for numerical variables to be kept unchanged\n",
        "    transformers=[\n",
        "        (\"cat\", categorical_transformer, categorical_X_features)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "_eJ6L3I29mQX",
        "outputId": "3fe07e14-7f9a-4243-f5fe-2a7708f35532"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0             1             2             3             4    \\\n",
              "count  21971.000000  21971.000000  21971.000000  21971.000000  21971.000000   \n",
              "mean       0.250603      0.571845      0.141232      0.032497      0.003823   \n",
              "std        0.433370      0.494823      0.348268      0.177321      0.061715   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "75%        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                5             6             7             8             9    \\\n",
              "count  21971.000000  21971.000000  21971.000000  21971.000000  21971.000000   \n",
              "mean       0.225342      0.555414      0.215921      0.003323      0.148195   \n",
              "std        0.417817      0.496931      0.411469      0.057547      0.355302   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "       ...           925           926           927           928  \\\n",
              "count  ...  21971.000000  21971.000000  21971.000000  21971.000000   \n",
              "mean   ...      0.034682      0.043557      0.141778      0.034591   \n",
              "std    ...      0.182977      0.204113      0.348830      0.182746   \n",
              "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                929           930           931           932           933  \\\n",
              "count  21971.000000  21971.000000  21971.000000  21971.000000  21971.000000   \n",
              "mean       0.051613      1.544581     51.483638      2.184835      0.256611   \n",
              "std        0.221250      0.498020     18.164264      1.097736      0.676453   \n",
              "min        0.000000      1.000000     15.000000      1.000000      0.000000   \n",
              "25%        0.000000      1.000000     37.000000      2.000000      0.000000   \n",
              "50%        0.000000      2.000000     53.000000      2.000000      0.000000   \n",
              "75%        0.000000      2.000000     66.000000      3.000000      0.000000   \n",
              "max        1.000000      2.000000     98.000000     20.000000     20.000000   \n",
              "\n",
              "                934  \n",
              "count  21971.000000  \n",
              "mean       0.757908  \n",
              "std        0.428359  \n",
              "min        0.000000  \n",
              "25%        1.000000  \n",
              "50%        1.000000  \n",
              "75%        1.000000  \n",
              "max        1.000000  \n",
              "\n",
              "[8 rows x 935 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41e474ea-14e2-4f0d-b5b6-58c80cbc65dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>925</th>\n",
              "      <th>926</th>\n",
              "      <th>927</th>\n",
              "      <th>928</th>\n",
              "      <th>929</th>\n",
              "      <th>930</th>\n",
              "      <th>931</th>\n",
              "      <th>932</th>\n",
              "      <th>933</th>\n",
              "      <th>934</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "      <td>21971.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.250603</td>\n",
              "      <td>0.571845</td>\n",
              "      <td>0.141232</td>\n",
              "      <td>0.032497</td>\n",
              "      <td>0.003823</td>\n",
              "      <td>0.225342</td>\n",
              "      <td>0.555414</td>\n",
              "      <td>0.215921</td>\n",
              "      <td>0.003323</td>\n",
              "      <td>0.148195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034682</td>\n",
              "      <td>0.043557</td>\n",
              "      <td>0.141778</td>\n",
              "      <td>0.034591</td>\n",
              "      <td>0.051613</td>\n",
              "      <td>1.544581</td>\n",
              "      <td>51.483638</td>\n",
              "      <td>2.184835</td>\n",
              "      <td>0.256611</td>\n",
              "      <td>0.757908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.433370</td>\n",
              "      <td>0.494823</td>\n",
              "      <td>0.348268</td>\n",
              "      <td>0.177321</td>\n",
              "      <td>0.061715</td>\n",
              "      <td>0.417817</td>\n",
              "      <td>0.496931</td>\n",
              "      <td>0.411469</td>\n",
              "      <td>0.057547</td>\n",
              "      <td>0.355302</td>\n",
              "      <td>...</td>\n",
              "      <td>0.182977</td>\n",
              "      <td>0.204113</td>\n",
              "      <td>0.348830</td>\n",
              "      <td>0.182746</td>\n",
              "      <td>0.221250</td>\n",
              "      <td>0.498020</td>\n",
              "      <td>18.164264</td>\n",
              "      <td>1.097736</td>\n",
              "      <td>0.676453</td>\n",
              "      <td>0.428359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 935 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41e474ea-14e2-4f0d-b5b6-58c80cbc65dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41e474ea-14e2-4f0d-b5b6-58c80cbc65dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41e474ea-14e2-4f0d-b5b6-58c80cbc65dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Inspect the number of variables after pre-processing\n",
        "# Fit the pipeline to the training data\n",
        "preprocessor.fit(X_train)\n",
        "X_train_ = preprocessor.transform(X_train)\n",
        "\n",
        "X_train_df = pd.DataFrame(data=X_train_)\n",
        "X_train_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBFgZlBkyl2p"
      },
      "source": [
        "### Model 1 (Baseline): Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C0154btCRIEf"
      },
      "outputs": [],
      "source": [
        "# Define a pipeline with pre-processing and a Logistic Regression\n",
        "logistic_regression_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter = 1000))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrMb4C8TJ-t-",
        "outputId": "5ffceb5d-9ff0-4b54-df49-d723f35aca3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.793934 using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.690273 (0.013640) with: {'classifier__C': 0.0001, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.689648 (0.012702) with: {'classifier__C': 0.0001, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.784627 (0.011048) with: {'classifier__C': 0.001, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.784382 (0.010895) with: {'classifier__C': 0.001, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.793762 (0.009960) with: {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.793934 (0.009774) with: {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.791880 (0.009457) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.791915 (0.009472) with: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
            "0.790942 (0.009412) with: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
            "0.790997 (0.009518) with: {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n"
          ]
        }
      ],
      "source": [
        "# Tune the hyperparameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define parameters for optimisiation\n",
        "solvers = ['liblinear', 'lbfgs'] # algorithms used to solve the optimization problem\n",
        "penalty = ['l2'] # specifying penaltty - limited to l2 as other penalties not compatible with all solvers\n",
        "c_values = [0.0001, 0.001, 0.01, 0.1, 1.0] # inverse of regularization strength (smaller values = stronger regularization)\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__solver':solvers, \n",
        "    'classifier__penalty':penalty,\n",
        "    'classifier__C':c_values}\n",
        "\n",
        "# Set-up repeated, stratified cross-validation \n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
        "\n",
        "# Define GridSearchCV with F1 as comparison metrics\n",
        "grid_search = GridSearchCV(estimator=logistic_regression_pipe, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='f1')\n",
        "\n",
        "# Fit the grid search model\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the mean test scrore (F1), sd and the parameters that were used\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_0qmTlj4jo3",
        "outputId": "2bb0a804-32ef-46f2-87e5-e39b6d375d7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./models/best-logistic-regression-model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Save the best model specification as a joblib file\n",
        "from joblib import dump, load\n",
        "\n",
        "best_logistic_estimator = grid_result.best_estimator_\n",
        "dump(best_logistic_estimator, './models/best-logistic-regression-model.joblib')\n",
        "\n",
        "best_logistic_params = grid_result.best_params_\n",
        "dump(best_logistic_params, './models/best-params-logistic-regression-model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfqsH6Vuyter"
      },
      "source": [
        "### Model 2: Naive Bayes\n",
        "Resulting from the One Hot Encoding in our pre-processing pipeline, the vast majority of our features is binary. Thus, the Bernoulli NB seems the most suitable NB model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EWOuMM6tgyFi"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Define a pipeline with pre-processing and a Bernoulli Naive Bayes\n",
        "naive_bayes_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", BernoulliNB())]\n",
        ")\n",
        "\n",
        "# Set-up repeated, stratified cross-validation \n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=123)\n",
        "\n",
        "# Get cross-validation score\n",
        "cv_results = cross_validate(estimator = naive_bayes_pipe, X=X_train, y=y_train, cv=cv, scoring='f1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model specification as a joblib file\n",
        "dump(naive_bayes_pipe, './models/best-nb-model.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEbkmEyZl1ik",
        "outputId": "4631629d-8d3b-4cd4-f9ed-8e282087bc26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./models/best-nb-model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ-Cg-wUtUpa"
      },
      "source": [
        "### Model 3: Support Vector Machine (SVM) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UTp9ZecFtl2A"
      },
      "outputs": [],
      "source": [
        "# Define a pipeline with pre-processing and SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", SVC())]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model specification as a joblib file\n",
        "dump(SVM_pipe, './models/best-svm-model.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wy0ZkM7m6co",
        "outputId": "9c04633f-c531-44f6-b0b2-da7f66113587"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./models/best-svm-model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1II1_71s_Lj"
      },
      "source": [
        "### Model 4: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XcbJwdgP-pCG"
      },
      "outputs": [],
      "source": [
        "# Define a pipeline with pre-processing and Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest_pipe = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier(random_state = 123))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaoHhXuW-ppj",
        "outputId": "bb559bdb-2824-497a-f7ce-3388fd5c9e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.820081 using {'classifier__n_estimators': 944, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'auto', 'classifier__max_depth': 90}\n",
            "0.819156 (0.005838) with: {'classifier__n_estimators': 733, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 20}\n",
            "0.819535 (0.005916) with: {'classifier__n_estimators': 1155, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'auto', 'classifier__max_depth': 60}\n",
            "0.819156 (0.005804) with: {'classifier__n_estimators': 1577, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 20}\n",
            "0.818746 (0.005514) with: {'classifier__n_estimators': 2000, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'auto', 'classifier__max_depth': 100}\n",
            "0.817790 (0.005605) with: {'classifier__n_estimators': 100, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 70}\n",
            "0.819580 (0.005642) with: {'classifier__n_estimators': 944, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 80}\n",
            "0.819338 (0.005689) with: {'classifier__n_estimators': 1155, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 100}\n",
            "0.816774 (0.005268) with: {'classifier__n_estimators': 1788, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 10}\n",
            "0.819034 (0.005844) with: {'classifier__n_estimators': 733, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'auto', 'classifier__max_depth': 60}\n",
            "0.818928 (0.005691) with: {'classifier__n_estimators': 1366, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'auto', 'classifier__max_depth': 50}\n",
            "0.820081 (0.005785) with: {'classifier__n_estimators': 944, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'auto', 'classifier__max_depth': 90}\n",
            "0.819535 (0.005916) with: {'classifier__n_estimators': 1155, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 100}\n",
            "0.818852 (0.005820) with: {'classifier__n_estimators': 944, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'auto', 'classifier__max_depth': 60}\n",
            "0.818700 (0.005486) with: {'classifier__n_estimators': 311, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 80}\n",
            "0.818700 (0.005577) with: {'classifier__n_estimators': 733, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'auto', 'classifier__max_depth': 40}\n",
            "0.818488 (0.005181) with: {'classifier__n_estimators': 1366, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'auto', 'classifier__max_depth': 20}\n",
            "0.818412 (0.005356) with: {'classifier__n_estimators': 1788, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 110}\n",
            "0.819960 (0.005847) with: {'classifier__n_estimators': 1577, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'auto', 'classifier__max_depth': 60}\n",
            "0.819414 (0.005275) with: {'classifier__n_estimators': 1155, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 70}\n",
            "0.816743 (0.005465) with: {'classifier__n_estimators': 733, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'auto', 'classifier__max_depth': 10}\n"
          ]
        }
      ],
      "source": [
        "# Define parameters for optimisiation\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)] # number of trees in the random forest\n",
        "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # maximum number of levels allowed in each decision tree\n",
        "min_samples_split = [2, 5, 10] # minimum sample number to split a node\n",
        "min_samples_leaf = [1, 2, 4] # minimum sample number that can be stored in a leaf node\n",
        "\n",
        "random_grid = {\n",
        "    'classifier__n_estimators':n_estimators, \n",
        "    'classifier__max_features':max_features,\n",
        "    'classifier__max_depth':max_depth,\n",
        "    'classifier__min_samples_split':min_samples_split,\n",
        "    'classifier__min_samples_leaf': min_samples_leaf}\n",
        "\n",
        "# Set-up repeated, stratified cross-validation \n",
        "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=123) # set n_splits to 5 for faster computation, tbd if increase for final run\n",
        "\n",
        "# Define GridSearchCV with F1 as comparison metrics\n",
        "rf_random = RandomizedSearchCV(estimator = random_forest_pipe, param_distributions=random_grid, cv=cv, n_iter=20, random_state=123, n_jobs = -1) \n",
        "# set number of iterations to 5 from the default of 10 for faster computation \n",
        "\n",
        "# Fit the grid search model\n",
        "rf_random_result = rf_random.fit(X_train, y_train)\n",
        "\n",
        "# Print the mean test scrore (F1), sd and the parameters that were used\n",
        "print(\"Best: %f using %s\" % (rf_random_result.best_score_, rf_random_result.best_params_))\n",
        "means = rf_random_result.cv_results_['mean_test_score']\n",
        "stds = rf_random_result.cv_results_['std_test_score']\n",
        "params = rf_random_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "vz8u3gQ6vnk2",
        "outputId": "faea162a-beae-40c4-f908-0917e321cd73"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5fabcd18dc5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'./models/best-rf-model.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/best-rf-model.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
          ]
        }
      ],
      "source": [
        "# Save the best model specification as a joblib file\n",
        "best_rf_estimator = rf_random_result.best_estimator_\n",
        "dump(best_rf_estimator, './models/best-rf-model.joblib')\n",
        "\n",
        "best_rf_params = rf_random.best_params_\n",
        "dump(best_rf_params, './models/best-params-rf-model.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDCTYXsTozY9"
      },
      "source": [
        "**Comparing the best performing models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "jyliL1IDHbrr",
        "outputId": "fc840fb1-fa63-4612-aab2-98b5530eafec"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a0f631286440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load all the model specifications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best-logistic-regression.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Naive Bayes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaive_bayes_pipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best-SVM.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load' is not defined"
          ]
        }
      ],
      "source": [
        "# Compare best performing models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load all the model specifications\n",
        "models = []\n",
        "models.append(('Logistic Regression', load(\"best-logistic-regression.joblib\")))\n",
        "models.append(('Naive Bayes', naive_bayes_pipe))\n",
        "models.append(('SVM', load(\"best-SVM.joblib\")))\n",
        "\n",
        "# Create lists for scores and model names. Comparison metric F1\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'f1'\n",
        "\n",
        "for name, model in models:\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=123)\n",
        "  cv_results = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring) # change to x test and y test in final run\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 ('Machine-Learning-Project-K3kAtfCK')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d776d6ed3af7d3b49847a0099a298aa8d78d20c8f42c0601505d3117fd4dfc67"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}