{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMju52rxZLizy4G46qVWK9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OskarKrafft/Machine-Learning-Project/blob/main/SHAP_Copy_for_Oskar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRmfZ-Cu9ejH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgsf3tlRE_Z7",
        "outputId": "ea988f29-a4ce-47ea-9bbc-926140b2ff47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project\n"
          ]
        }
      ],
      "source": [
        "# Mounting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory to project folder\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTmh44O0FPfv",
        "outputId": "ec0a7ca1-7afc-4260-839f-1cb7144677c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Machine-Learning-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Test Data"
      ],
      "metadata": {
        "id": "Adpkt_WHFiJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the data\n",
        "import pandas as pd\n",
        "eppes_cleaned = pd.read_csv('./data/processed/eppes_cleaned.csv')\n",
        "eppes_cleaned = eppes_cleaned.drop(eppes_cleaned.columns[0], axis = 1)\n",
        "\n",
        "# Import Excel sheet containing column indeces to be dropped\n",
        "columns_analysis = pd.read_excel('./data/interim/Drop_Columns_categorical.xlsx')\n",
        "columns_analysis = columns_analysis.drop(columns_analysis.columns[[0]], axis = 1)\n",
        "\n",
        "# Create list of names of categorical columns \n",
        "col_names_categorical = []\n",
        "for i in range(872):\n",
        "  if columns_analysis.iloc[i, 3] == 'categorical':\n",
        "    col_names_categorical.append(columns_analysis.iloc[i, 1])\n",
        "\n",
        "# Change datatype of categorical variables to object\n",
        "eppes_cleaned[col_names_categorical] = eppes_cleaned[col_names_categorical].astype('object')\n",
        "\n",
        "# Define X and y\n",
        "print(eppes_cleaned.head())\n",
        "X = eppes_cleaned.drop(columns='qg1') # reference variable which contains voted y/n\n",
        "y = eppes_cleaned['qg1'] # reference variable which contains voted y/n\n",
        "\n",
        "# 80/20 train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state=123)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_test = label_encoder.fit_transform(y_test)\n",
        "\n",
        "y_test_df = pd.DataFrame(data=y_test)\n",
        "y_test_df.value_counts(normalize=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "\n",
        "y_train_df = pd.DataFrame(data=y_train)\n",
        "y_train_df.value_counts(normalize=True)\n",
        "\n",
        "# Setting up pre-processing pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Identify all categorical variables by data type\n",
        "categorical_X_features = X_test.select_dtypes(include=['object', 'bool']).columns\n",
        "\n",
        "# OneHotEncode all categorical variables\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"error\")\n",
        "\n",
        "preprocessor = ColumnTransformer(remainder = 'passthrough', # remainder = passthrough for numerical variables to be kept unchanged\n",
        "    transformers=[\n",
        "        (\"cat\", categorical_transformer, categorical_X_features)]\n",
        ")\n",
        "# Inspect the number of variables after pre-processing\n",
        "\n",
        "# Fit the pipeline to the testing data\n",
        "preprocessor.fit(X_test)\n",
        "X_test_ = preprocessor.transform(X_test)\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "preprocessor.fit(X_train)\n",
        "X_train_ = preprocessor.transform(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyKFRo8yFfvy",
        "outputId": "20db20b0-d2db-4e94-e46c-69053ff2d4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   q1.1  q1.2  q1.3  q1.4  q1.5  q1.6  q1.7  q1.8  q1.9  q1.10  ...  d43a  \\\n",
            "0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "1   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "2   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   2.0   \n",
            "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0  ...   1.0   \n",
            "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0    0.0  ...   2.0   \n",
            "\n",
            "   d43b  d46.8  d60  d62_1  d62_2  d63  d72_1  d72_2  d77  \n",
            "0   1.0    1.0  1.0    3.0    6.0  1.0    3.0    3.0  2.0  \n",
            "1   1.0    1.0  3.0    2.0    6.0  3.0    2.0    2.0  3.0  \n",
            "2   2.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  1.0  \n",
            "3   1.0    1.0  2.0    1.0    1.0  3.0    2.0    2.0  1.0  \n",
            "4   1.0    1.0  1.0    1.0    5.0  2.0    2.0    2.0  3.0  \n",
            "\n",
            "[5 rows x 311 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Models"
      ],
      "metadata": {
        "id": "WCxZFl8lFux8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "best_rf = RandomForestClassifier(max_depth = 90, n_estimators = 944, min_samples_split = 2, min_samples_leaf = 1, max_features = \"auto\", random_state = 123)"
      ],
      "metadata": {
        "id": "uaKvPmHoFx0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf.fit(X_train_, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJP9q9wOGEpd",
        "outputId": "49ca003c-5193-43e6-9251-961df367d7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=90, n_estimators=944, random_state=123)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = best_rf.predict(X_test_)"
      ],
      "metadata": {
        "id": "h6KHPaiXib4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef, f1_score, accuracy_score, precision_score, recall_score\n",
        "mcc = []\n",
        "f1 = []\n",
        "\n",
        "mcc.append((matthews_corrcoef(y_test, y_pred_rf)))\n",
        "f1.append((f1_score(y_test, y_pred_rf)))"
      ],
      "metadata": {
        "id": "bS5es02eij0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcc\n",
        "f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHdI-iFrixjE",
        "outputId": "e3c81876-32a3-4445-f3ac-973f08d2cc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8064188502945359]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByIBHymSHJeO",
        "outputId": "b1fa5f49-ef74-4d41-c73e-ec19c1a961ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.41.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.56.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.7.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.5.0)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.21.6)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba->shap) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.39.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba->shap) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap "
      ],
      "metadata": {
        "id": "gA77QEW5GPJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(best_rf)\n",
        "shap_test = explainer(X_test_)\n",
        "print(f\"Shap values length: {len(shap_test)}\\n\")\n",
        "print(f\"Sample shap value:\\n{shap_test[0]}\")"
      ],
      "metadata": {
        "id": "1qF27K1aLF_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_test)"
      ],
      "metadata": {
        "id": "-FlX5S5ularT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}